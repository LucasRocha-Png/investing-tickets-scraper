Metadata-Version: 2.1
Name: investing-tickets-scrapper
Version: 0.0.4
Summary: Scraps stock tickets from "Investing.com" using Selenium and parse using BeautifulSoup
Home-page: UNKNOWN
Author: Lucas Rocha
Author-email: lucasrocha.png@gmail.com
License: UNKNOWN
Keywords: python,tickers,index,stocks,exchange,investing
Platform: UNKNOWN
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: Unix
Classifier: Operating System :: MacOS :: MacOS X
Classifier: Operating System :: Microsoft :: Windows
Description-Content-Type: text/markdown
License-File: LICENSE.txt

# investing-tickets-scrapper
#### This package scraps all tickets available from "investing.com" site

## How to install
Installing "investing-tickets-scrapper" from pypi (recomended).
```bash
pip install investing-tickets-scrapper
```

#### or

Installing "investing-tickets-scrapper" using the repository.
```bash
pip install -e .
```

## How to use

```python
# Import the library
from investing_tickets_scrapper.scrapper import Scrapper
import pandas as pd

# Create the object scrapper using the imported class
scrapper = Scrapper()

# Configurates the scrapper
scrapper.config(chromedriver_path="C:\Program Files (x86)\chromedriver.exe", # Chromedriver_path = chromedriver for Selenium, if you don't know what is it, check this video "https://youtu.be/Xjv1sY630Uc" and install it
                country="United States")  # Country = the country you want to scrap the tickeks. To check all countries available you can use "print(scrapper.contries_available())"
                                                                                                      
# Start scrapping
scrapper.scrap() # It will open the Google Chrome and scrap it. Is recommended not to use the mouse and the keboard

# Return the data as a pandas dataframe
df = scrapper.return_dataframe()
print(df) # df
```


